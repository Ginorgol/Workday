import nltk

from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import confusion_matrix
from sklearn import metrics
from nltk.stem.porter import PorterStemmer

from sklearn.model_selection import GridSearchCV

import re

from xgboost import XGBClassifier

import string
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.stem.wordnet import WordNetLemmatizer

import pickle

import os

from bs4 import BeautifulSoup

# https://stackoverflow.com/a/47091490/4084039
import re

def decontracted(phrase):
    # specific
    phrase = re.sub(r"won't", "will not", phrase)
    phrase = re.sub(r"can\'t", "can not", phrase)

    # general
    phrase = re.sub(r"n\'t", " not", phrase)
    phrase = re.sub(r"\'re", " are", phrase)
    phrase = re.sub(r"\'s", " is", phrase)
    phrase = re.sub(r"\'d", " would", phrase)
    phrase = re.sub(r"\'ll", " will", phrase)
    phrase = re.sub(r"\'t", " not", phrase)
    phrase = re.sub(r"\'ve", " have", phrase)
    phrase = re.sub(r"\'m", " am", phrase)
    return phrase

stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', "you're", "you've",\
        "you'll", "you'd", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \
        'she', "she's", 'her', 'hers', 'herself', 'it', "it's", 'its', 'itself', 'they', 'them', 'their',\
        'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', "that'll", 'these', 'those', \
        'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \
        'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \
        'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\
        'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\
        'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\
        'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \
        's', 't', 'can', 'will', 'just', 'don', "don't", 'should', "should've", 'now', 'd', 'll', 'm', 'o', 're', \
        've', 'y', 'ain', 'aren', "aren't", 'couldn', "couldn't", 'didn', "didn't", 'doesn', "doesn't", 'hadn',\
        "hadn't", 'hasn', "hasn't", 'haven', "haven't", 'isn', "isn't", 'ma', 'mightn', "mightn't", 'mustn',\
        "mustn't", 'needn', "needn't", 'shan', "shan't", 'shouldn', "shouldn't", 'wasn', "wasn't", 'weren', "weren't", \
        'won', "won't", 'wouldn', "wouldn't"])


def preprocess(val):
    short_desc = []
    for sentance in val:
        sentance = re.sub(r"http\S+", "", sentance)
        sentance = BeautifulSoup(sentance, 'lxml').get_text()
        sentance = decontracted(sentance)
        sentance = re.sub("\S*\d\S*", "", sentance).strip()
        sentance = re.sub('[^A-Za-z]+', ' ', sentance)
        sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)
        short_desc.append(sentance.strip())
    return short_desc


with open("clf_assigned_group_150k.pickle", 'rb') as f:
    clf_assigned_group_150k = pickle.load(f)

with open('clf_incidents_product_6k.pickle', 'rb') as f:
    clf_incidents_product_6k = pickle.load(f)


with open('clf_level_product_6k.pickle', 'rb') as f:
    clf_level_product_6k = pickle.load(f)


with open('tf_idf_vect_assigned_group_150k.pickle', 'rb') as f:
    tf_idf_vect_assigned_group_150k = pickle.load(f)


with open('tf_idf_vect_incidents_product_6k.pickle', 'rb') as f:
    tf_idf_vect_incidents_product_6k = pickle.load(f)


with open('tf_idf_vect_level_product_6k.pickle', 'rb') as f:
    tf_idf_vect_level_product_6k = pickle.load(f)


def make_prediction_(description):
    res = {}
    cleaned_description = preprocess(description)
    tf_idf = tf_idf_vect_incidents_product_6k.transform(cleaned_description)
    res['product_6k'] = clf_incidents_product_6k.predict(tf_idf)
    tf_idf = tf_idf_vect_level_product_6k.transform(cleaned_description)
    res['level_6k'] = clf_level_product_6k.predict(tf_idf)
    tf_idf = tf_idf_vect_assigned_group_150k.transform(cleaned_description)
    res['assigned_group_150k'] = clf_assigned_group_150k.predict(tf_idf)
    return res

print(make_prediction_(['microsoft outlook is not working']))